<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.cdnfonts.com/css/apple-garamond" rel="stylesheet">
    <title>Simon Kolker</title>

    <link rel="apple-touch-icon" sizes="180x180" href="favicon_io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon_io//favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon_io//favicon-16x16.png">
    <link rel="manifest" href="favicon_io/site.webmanifest">

</head>
<body>
    <div class="toolbar">
        <div class="toolbar-button"><a href="https://github.com/sameysimon">GitHub</a></div>
        <div class="toolbar-button"><a href="https://research.manchester.ac.uk/en/persons/simon.kolker">University of Manchester</a></div>
        <div class="toolbar-button"><a href="https://www.linkedin.com/in/simonkolker/">LinkedIn</a></div>
    </div>

    
    <div class="header">
        <div class="title">
            <h1>Simon Kolker</h1>
            <div class="info">            
                A PhD Candidate at the University of Manchester
            </div>

 
        </div>
    </div>

    <div class="content">
        <div class="block">
            <h2>Research Focus</h2>
            <p>
                I am a PhD student in the Department of Computer Science at the University of Manchester.
                Particularly, my project aims to study the effect of uncertainty on Machine Ethics. As autonomous systems take more responsibility in the real world, the consequences of their actions reach into every facet of our lives. 
            </p>
            <p>
                The need arises for explicit ethical reasoning in autonomous systems. This is a problem of Philosophy. How can a stakeholder's notion of morality be encoded for machines? How can we verify a machine will act accordingly? And how should such a system act under uncertainty?
            </p>

        </div>
        <div class="block">
            <h2>Roles</h2>
            <ul>
                <li>Member of the <a href="https://autonomy-and-verification.github.io/">Autonomy and Verification Network</a></li>
                <li>Publicity Chair for <a href="http://https://smcit-scc.space/">IEEE Space Mission Chalenges for Information Technology IEEE Space Computing Conference</a> </li>
            </ul>
        </div>
        <div class="block">
            <h2>Publications</h2>
            <div class="publication">
                <p><b>Machine Ethical Decisions with Hypothetical Retrospection</b></p>
                <p>Simon Kolker, Louise Dennis, Ramon Fraga Pereira, and Mengwei Xu</p>
                <p>In International Workshop on Coordination, Organizations, Institutions, Norms and Ethics for Governance of Multi-Agent Systems (COINE), To appear. 2023</p>
                <p>
                    <a href="https://arxiv.org/abs/2305.01424">[Arxiv]</a>
                    <a href="https://github.com/sameysimon/HypotheticalRetrospectionMachine">[Code]</a>
                </p>
            </div>
            <div class="publication">
                <p><b>Selecting Ethical Actions by Retrospection on Hypothetical Outcomes</b></p>
                <p>Simon Kolker, Louise Dennis, Ramon Fraga Pereira, and Mengwei Xu</p>
                <p>In International Workshop on Computational Machine Ethics (CME) 2023</p>
                <p>
                    <a href="">[Arxiv]</a>
                </p>
            </div>
        </div>
    </div>
    
</body>
</html>


